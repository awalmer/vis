session_type = as.factor(session_type),
evergreen = as.logical(evergreen),
canceled = as.logical(canceled),
recorded = as.logical(recorded),
day = fct_relevel(as_factor(day), "Thursday", "Friday", "Saturday", "Sunday"), # using fct_relevel to specify the order
start_time_utc = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
end_time_utc = as.POSIXct(end_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
cost = as.numeric(cost),
start_time_example = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
)
str(sessions,max.level=1) #checking to see if the changes were made
sessions <- sessions %>%
mutate(
start_time_pt = with_tz(start_time_utc, tzone = "America/Los_Angeles"),
end_time_pt = with_tz(end_time_utc, tzone = "America/Los_Angeles")
)
library(lubridate)
lubridate::ymd_hms
library(lubridate)
lubridate::ymd_hms
sessions <- sessions %>%
mutate(
start_time_pt = with_tz(start_time_utc, tzone = "America/Los_Angeles"),
end_time_pt = with_tz(end_time_utc, tzone = "America/Los_Angeles"),
duration_2 = as.duration(end_time_pt-start_time_pt)
)
str(sessions,max.level=1)
sessions <- sessions %>%
select(-start_time_utc, -end_time_utc,-start_time,-end_time) %>%
rename(start_time = start_time_pt, end_time = end_time_pt) #renaming the columns to reflect the new time zone
sessions <- sessions %>%
select(-start_time_utc, -end_time_utc,-start_time,-end_time) %>%
rename(start_time = start_time_pt, end_time = end_time_pt) #renaming the columns to reflect the new time zone
sessions <- sessions %>%
mutate(
start_time_pt = with_tz(start_time_utc, tzone = "America/Los_Angeles"),
end_time_pt = with_tz(end_time_utc, tzone = "America/Los_Angeles"),
duration_2 = as.duration(end_time_pt-start_time_pt)
)
sessions <- sessions %>%
mutate(
track = as_factor(track),
session_type = as.factor(session_type),
evergreen = as.logical(evergreen),
canceled = as.logical(canceled),
recorded = as.logical(recorded),
day = fct_relevel(as_factor(day), "Thursday", "Friday", "Saturday", "Sunday"), # using fct_relevel to specify the order
start_time_utc = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
end_time_utc = as.POSIXct(end_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
cost = as.numeric(cost),
start_time_example = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
)
str(sessions,max.level=1) #checking to see if the changes were made
library(lubridate)
lubridate::ymd_hms
sessions <- sessions %>%
mutate(
start_time_pt = with_tz(start_time_utc, tzone = "America/Los_Angeles"),
end_time_pt = with_tz(end_time_utc, tzone = "America/Los_Angeles"),
duration_2 = as.duration(end_time_pt-start_time_pt)
)
str(sessions,max.level=1)
sessions <- sessions %>%
select(-start_time_utc, -end_time_utc,-start_time,-end_time) %>%
rename(start_time = start_time_pt, end_time = end_time_pt) #renaming the columns to reflect the new time zone
str(sessions,max.level=1)
sessions %>% count(recorded) #counting the number of TRUE and FALSE values in the canceled column
not_recorded <- sessions %>% filter(recorded == "FALSE")
future_not_recorded <- not_recorded %>% filter(day %in% c("Saturday", "Sunday")) #filtering for the future sessions that won't be recorded
#Or if we want to find future not-recorded sessions in a programmatic way that will work at any point in time
future_not_recorded <- not_recorded %>% filter(start_time > Sys.time())
ideal_sessions <- future_not_recorded %>% filter(evergreen == FALSE & canceled == FALSE & !grepl("registration",session_type,ignore.case=TRUE) & (grepl("Edit",track,ignore.case=TRUE) | grepl("manag",track,ignore.case=TRUE) | grepl("writing",track,ignore.case=TRUE) | track=="" | grepl("elect",track,ignore.case=TRUE)))
ideal_handson <- ideal_sessions %>% filter(session_type == "Hands-on")
sessions <- session %>%
filter(canceled == FALSE) %>%
filter(grepl("data",track,ignore.case=TRUE))
sessions <- sessions %>%
filter(canceled == FALSE) %>%
filter(grepl("data",track,ignore.case=TRUE))
View(sessions)
sessions <- sessions %>%
filter(canceled == FALSE) %>%
filter(grepl("data",track,ignore.case=TRUE)) %>%
filter(recorded == FALSE)
sessions <- sessions %>%
mutate(
track = as_factor(track),
session_type = as.factor(session_type),
evergreen = as.logical(evergreen),
canceled = as.logical(canceled),
recorded = as.logical(recorded),
day = fct_relevel(as_factor(day), "Thursday", "Friday", "Saturday", "Sunday"), # using fct_relevel to specify the order
start_time_utc = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
end_time_utc = as.POSIXct(end_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
cost = as.numeric(cost),
start_time_example = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
)
str(sessions,max.level=1) #checking to see if the changes were made
We see that the start time in the original data, and in the cleaned data, is in UTC. We can convert this to the local time zone of the conference, which is Pacific Time.
```{r}
library(lubridate)
lubridate::ymd_hms
sessions <- sessions %>%
mutate(
start_time_pt = with_tz(start_time_utc, tzone = "America/Los_Angeles"),
end_time_pt = with_tz(end_time_utc, tzone = "America/Los_Angeles"),
duration_2 = as.duration(end_time_pt-start_time_pt)
)
str(sessions,max.level=1)
sessions <- sessions %>%
select(-start_time_utc, -end_time_utc,-start_time,-end_time) %>%
rename(start_time = start_time_pt, end_time = end_time_pt) #renaming the columns to reflect the new time zone
str(sessions,max.level=1)
sessions %>% count(recorded) #counting the number of TRUE and FALSE values in the canceled column
not_recorded <- sessions %>% filter(recorded == "FALSE")
future_not_recorded <- not_recorded %>% filter(day %in% c("Saturday", "Sunday")) #filtering for the future sessions that won't be recorded
#Or if we want to find future not-recorded sessions in a programmatic way that will work at any point in time
future_not_recorded <- not_recorded %>% filter(start_time > Sys.time())
ideal_sessions <- future_not_recorded %>% filter(evergreen == FALSE & canceled == FALSE & !grepl("registration",session_type,ignore.case=TRUE) & (grepl("Edit",track,ignore.case=TRUE) | grepl("manag",track,ignore.case=TRUE) | grepl("writing",track,ignore.case=TRUE) | track=="" | grepl("elect",track,ignore.case=TRUE)))
ideal_handson <- ideal_sessions %>% filter(session_type == "Hands-on")
sessions <- sessions %>%
filter(canceled == FALSE) %>%
filter(grepl("data",track,ignore.case=TRUE)) %>%
filter(recorded == FALSE)
glimpse(sessions)
sessions %>% count(recorded) #counting the number of TRUE and FALSE values in the canceled column
not_recorded <- sessions %>% filter(recorded == "FALSE")
future_not_recorded <- not_recorded %>% filter(day %in% c("Saturday", "Sunday")) #filtering for the future sessions that won't be recorded
ideal_sessions <- future_not_recorded %>% filter(evergreen == FALSE & canceled == FALSE & !grepl("registration",session_type,ignore.case=TRUE) & (grepl("Edit",track,ignore.case=TRUE) | grepl("manag",track,ignore.case=TRUE) | grepl("writing",track,ignore.case=TRUE) | track=="" | grepl("elect",track,ignore.case=TRUE)))
glimpse(ideal_sessions)
str(sessions$speakers[[1]],max.level=1)
all_speakers1 <- bind_rows(sessions$speakers) #binding all the speakers into one dataframe
glimpse(all_speakers1)
View(all_speakers1)
all_speakers2 <- sessions %>%
unnest(cols = speakers) #unnesting the speakers column
glimpse(all_speakers2)
View(all_speakers2)
all_speakers <- sessions %>%
select(session_id, session_title, speakers) %>%
unnest(cols=speakers)
glimpse(all_speakers)
View(all_speakers)
all_speakers %>%
count(name, sort = TRUE) #counting the number of sessions each speaker is in
#paste option
all_speakers1 <- all_speakers %>%
mutate(name = paste(first, last)) %>%
select(-first, -last) #combining the first and last name into one column
#unite option
all_speakers2 <- all_speakers %>%
unite(name, first, last, sep = " ", remove = FALSE) #combining the first and last name into one column with a space between them.
#lets just keep the paste option.
all_speakers <- all_speakers1
rm(all_speakers1,all_speakers2) #removing the other dataframes
all_speakers %>%
count(name, sort = TRUE) #counting the number of sessions each speaker is in
all_speakers %>%
count(name) %>%
count(n) #counting the number of speakers who are speaking once versus those speaking more than once
all_speakers %>%
count(name, sort = TRUE) #counting the number of sessions each speaker is in
library(devtools)
install.packages("devtools") # if not already installed on your system
devtools::install_github("munichrocker/DatawRappr")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools") # if not already installed on your system
devtools::install_github("munichrocker/DatawRappr")
library(devtools)
install.packages("devtools") # if not already installed on your system
install.packages("devtools")
library(devtools)
devtools::install_github("munichrocker/DatawRappr")
install.packages("devtools")
devtools::install_github("munichrocker/DatawRappr")
update.packages("rlang")
install.packages("devtools")
library(devtools)
packageVersion("rlang") # ‘1.0.6’
library(devtools)
remove.packages("rlang")
library(devtools)
packageVersion("rlang") # ‘1.0.6’
update.packages("rlang")
packageVersion("rlang")
install.packages("rlang")
install.packages("rlang")
packageVersion("rlang")
devtools::install_github("munichrocker/DatawRappr")
devtools::install_github("munichrocker/DatawRappr")
library(DatawRappr)
library(tidyverse)
datawrapper_auth(api_key =  "pgo0RQAWCOfL4vJeturiHaqzO1iQLgYqEEHvNMvZcveUVpTXww55FL0878G0Y1yP", overwrite=TRUE)
crime_data <- read.csv("mn-crime-data.csv")
head(crime_data)
View(crime_data)
crime_data$Year <- year(crime_data$Reported_Date)
crime_data <- crime_data %>%
filter(Year < 2025)
crime_summary <- crime_data %>%
count(Year)
nrow(crime_data)
sum(crime_summary$n)
crime_summary <- crime_summary %>%
rename("Reported crimes" = "n")
View(crime_data)
View(crime_summary)
my_chart <- dw_create_chart()
dw_data_to_chart(crime_summary, my_chart)
dw_edit_chart(my_chart, title = "Crime in Minneapolis hit a three-year low in 2024",
intro = "Reported crimes in the city between 2019 and 2024 hit a high mark in 2022 but have been on the decline since.", source_name = "Open Data Minneapolis")
dw_publish_chart(my_chart)
png_chart <- dw_export_chart(my_chart, type = "png")
magick::image_write(png_chart, "line-chart.png")
It should look like this:
bar_chart <- dw_create_chart(
type="d3-bars",
title="Minneapolis reported crime, 2019-2024"
)
dw_data_to_chart(crime_summary, bar_chart)
dw_edit_chart(bar_chart, title = "Crime in Minneapolis hit a three-year low in 2024",
intro = "Reported crimes in the city between 2019 and 2024 hit a high mark in 2022 but have been on the decline since.", source_name = "Open Data Minneapolis")
dw_retrieve_chart_metadata(bar_chart)
dw_edit_chart(bar_chart,
byline = "Adam Marton",
visualize = list(
"base-color" = "#a47764",
"thick" = "true",
"value-label-alignment" = "right"
)
)
dw_publish_chart(bar_chart)
crimes_2024 <- crime_data %>%
filter(Year == 2024)
crime_offense_summary <- crimes_2024 %>%
count(Offense_Category)
crime_offense_summary <- crime_offense_summary %>%
arrange(desc(n)) %>%
slice(1:10)
offense_chart <- dw_copy_chart(copy_from = "INSERT CHART ID FROM BAR CHART ABOVE")
offense_chart <- dw_copy_chart(copy_from = "INSERT CHART ID FROM BAR CHART ABOVE")
crime_offense_summary <- crime_offense_summary %>%
arrange(desc(n)) %>%
slice(1:10)
crime_offense_summary <- crime_offense_summary %>%
arrange(desc(n)) %>%
slice(1:10)
crime_offense_summary <- crimes_2024 %>%
count(Offense_Category)
crime_offense_summary <- crime_offense_summary %>%
arrange(desc(n)) %>%
slice(1:10)
dw_publish_chart(offense_chart)
offense_chart <- dw_copy_chart(copy_from = "U9ABN")
dw_data_to_chart(crime_offense_summary, offense_chart)
dw_edit_chart(offense_chart, title = "Top 10 highest categories of crime offenses in Minneapolis in 2024",
intro = "Almost 13,000 larceny and theft offenses and over 8,000 assault offenses were reported.", source_name = "Open Data Minneapolis")
dw_publish_chart(offense_chart)
dw_retrieve_chart_metadata(offense_chart)
dw_edit_chart(offense_chart,
visualize = list(
"base-color" = "#8ACE00",
"sort-bars" = "true",
"rules" = "true",
"background" = "true",
"block-labels" = "true",
"value-label-alignment" = "right"
)
)
dw_publish_chart(offense_chart)
crime_neighborhood_summary <- crimes_2024 %>%
count(Neighborhood)
crime_neighborhood_summary <- crime_neighborhood_summary %>%
arrange(desc(n)) %>%
slice(1:10)
my_function <- function() {
#make a new data frame that holds data just for precinct 1
precinct_data <- crime_data %>% filter(Precinct== 1)
#count number of arrests per year in that precinct
precinct_summary <- precinct_data %>%count(Year)
#create new chart
my_chart <- dw_create_chart(
type="d3-bars",
)
#add data
dw_data_to_chart(precinct_summary, my_chart)
#edit chart
dw_edit_chart(my_chart, title = paste("Reported crimes by year in Minneapolis Precinct 1"), source_name = "Open Data Minneapolis")
#publish
dw_publish_chart(my_chart)
}
#Call the function to run it
my_function()
#add a parameter called precinct
my_function <- function(precinct) {
#instead of naming the precinct here, use the parameter
precinct_data <- crime_data %>% filter(Precinct == precinct)
precinct_summary <- precinct_data %>%count(Year)
my_chart <- dw_create_chart(
type="d3-bars",
)
dw_data_to_chart(precinct_summary, my_chart)
#Again, use the parameter instead of naming the specific precinct in the headline
dw_edit_chart(my_chart, title = paste("Reported crimes by year in Minneapolis Precinct", precinct), source_name = "Open Data Minneapolis")
dw_publish_chart(my_chart)
}
#Call the function and pass an argument -- "2"-- to the parameter
#This passes the 2 everywhere we have the parameter in the function, so our graphic will display crimes in precinct 2
my_function("2")
for(precinct in unique(crime_data$Precinct)) {
my_function(precinct)
}
pixar_films <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/pixar_films.csv')
public_response <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/public_response.csv')
View(pixar_films)
View(public_response)
join()
join
View(pixar_films)
setwd("/Users/auraleewalmer/Documents/github-vis/vis/src/")
tuesdata <- tidytuesdayR::tt_load(2025, week = 36)
#country_lists <- tuesdata$country_lists
rank_by_year <- tuesdata$rank_by_year
rank_by_year$year <- as.integer(rank_by_year$year)
rank_by_year[, c("rank", "visa_free_count", "year")] <- lapply(rank_by_year[, c("rank", "visa_free_count", "year")], as.integer)
View(rank_by_year)
# Region Data Frame:
filterByRegion <- function(passport_data, region) {
region_data <- passport_data[passport_data$region==region,]
region_data_2025 <- region_data[region_data$year==2025,]
region_data_2025 <- region_data_2025[order(-region_data_2025$visa_free_count), ]
region_data_2025$region_rank_2025 <- seq(1, nrow(region_data_2025))
region_data <- left_join(region_data, region_data_2025[c("country","region_rank_2025")], by = "country")
region_data <- region_data[order(region_data$region_rank_2025), ]
return(region_data)
}
# Cleaned Region Data Frame:
cleanRegionData <- function(region_data, replace_0=c("yes","no"), remove_0709=c("yes","no")) {
cleandata <- region_data
if (replace_0=="yes") {
cleandata$visa_free_count[cleandata$visa_free_count==0] <- NA
} else {}
if (remove_0709=="yes") {
cleandata <- cleandata[cleandata$year!=2007 & cleandata$year!=2009,]
} else {}
return(cleandata)
}
replaceNames <- function(cleandata, number_name_replacements,
list_old_names, list_new_names) {
for (i in 1:number_name_replacements) {
cleandata$country[cleandata$country==list_old_names[[i]]] <- list_new_names[[i]]
}
return(cleandata)
}
dfWriteJSON <- function(list_dfs) {
for (d in 1:length(list_dfs)) {
name <- names(list_dfs)[[d]]
df <- list_dfs[[d]]
write_json(df, paste0("data/", name, "-passport.json"), stream = TRUE, pretty = TRUE)
}
}
#Asia:
asia <- filterByRegion(rank_by_year, "ASIA")
asia <- cleanRegionData(asia, replace_0="yes", remove_0709="yes")
asia_names_old <- list('Hong Kong (SAR China)', 'Macao (SAR China)', 'Taiwan (Chinese Taipei)')
library(tidytuesdayR)
library(httr)
library(tidyverse)
library(jsonlite)
dfWriteJSON <- function(list_dfs) {
for (d in 1:length(list_dfs)) {
name <- names(list_dfs)[[d]]
df <- list_dfs[[d]]
write_json(df, paste0("data/", name, "-passport.json"), stream = TRUE, pretty = TRUE)
}
}
#Asia:
asia <- filterByRegion(rank_by_year, "ASIA")
asia <- cleanRegionData(asia, replace_0="yes", remove_0709="yes")
asia_names_old <- list('Hong Kong (SAR China)', 'Macao (SAR China)', 'Taiwan (Chinese Taipei)')
asia_names_new <- list('Hong Kong', 'Macao', 'Taiwan')
asia <- replaceNames(asia, 3, asia_names_old, asia_names_new)
View(asia)
# Europe:
europe <- filterByRegion(rank_by_year, "EUROPE")
europe <- cleanRegionData(europe, replace_0="yes", remove_0709="yes")
View(europe)
europe_names_old <- list('Bosnia and Herzegovina')
europe_names_new <- list('Bosnia & Herzegovina')
europe <- replaceNames(europe, 1, europe_names_old, europe_names_new)
View(europe)
africa <- cleanRegionData(africa, replace_0="yes", remove_0709="yes")
# Africa:
africa <- filterByRegion(rank_by_year, "AFRICA")
africa <- cleanRegionData(africa, replace_0="yes", remove_0709="yes")
View(africa)
africa_names_old <- list('Cape Verde Islands', 'Central African Republic', 'Tome and Principe')
africa_names_new <- list('Cape Verde Isl.', 'Central African Rep.', 'Tome & Principe')
africa <- replaceNames(africa, n, africa_names_old, africa_names_new)
africa_names_new <- list('Cape Verde Isl.', 'Central African Rep.', 'Tome & Principe')
africa <- replaceNames(africa, 3, africa_names_old, africa_names_new)
View(africa)
africa <- replaceNames(africa, 3, africa_names_old, africa_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
View(europe)
europe_names_old <- list('Bosnia and Herzegovina')
europe_names_new <- list('Bosnia (B&H)')
europe <- replaceNames(europe, 1, europe_names_old, europe_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
europe_names_old <- list('Bosnia and Herzegovina')
europe_names_new <- list('Bosnia (B&H)')
europe <- replaceNames(europe, 1, europe_names_old, europe_names_new)
# Europe:
europe <- filterByRegion(rank_by_year, "EUROPE")
europe <- cleanRegionData(europe, replace_0="yes", remove_0709="yes")
europe_names_old <- list('Bosnia and Herzegovina')
europe_names_new <- list('Bosnia (B&H)')
europe <- replaceNames(europe, 1, europe_names_old, europe_names_new)
dfWriteJSON(region_df_list)
# Europe:
europe <- filterByRegion(rank_by_year, "EUROPE")
europe <- cleanRegionData(europe, replace_0="yes", remove_0709="yes")
europe_names_old <- list('Bosnia and Herzegovina')
europe_names_new <- list('Bosnia (B&H)')
europe <- replaceNames(europe, 1, europe_names_old, europe_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
europe_names_old <- list('Bosnia and Herzegovina', 'Russian Federation')
europe_names_new <- list('Bosnia (B&H)', 'Russian Fed.')
# Europe:
europe <- filterByRegion(rank_by_year, "EUROPE")
europe <- cleanRegionData(europe, replace_0="yes", remove_0709="yes")
europe_names_old <- list('Bosnia and Herzegovina', 'Russian Federation')
europe_names_new <- list('Bosnia (B&H)', 'Russian Fed.')
europe <- replaceNames(europe, 2, europe_names_old, europe_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
# Africa:
africa <- filterByRegion(rank_by_year, "AFRICA")
africa <- cleanRegionData(africa, replace_0="yes", remove_0709="yes")
africa_names_old <- list('Cape Verde Islands', 'Central African Republic', 'Sao Tome and Principe')
africa_names_new <- list('Cape Verde Isl.', 'Centr. African Rep.', 'Sao Tome & Princ.')
africa <- replaceNames(africa, 3, africa_names_old, africa_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa)
dfWriteJSON(region_df_list)
unique(rank_by_year$region)
unique(rank_by_year[rank_by_year$region=='OCEANIA']$country)
unique(rank_by_year[rank_by_year$region=='OCEANIA',]$country)
unique(rank_by_year[rank_by_year$region=='CARIBBEAN',]$country)
unique(rank_by_year[rank_by_year$region=='AMERICAS',]$country)
unique(rank_by_year[rank_by_year$region=='AFRICA',]$country)
unique(rank_by_year[rank_by_year$region=='europe',]$country)
unique(rank_by_year[rank_by_year$region=='EUROPE',]$country)
unique(rank_by_year[rank_by_year$region=='ASIA',]$country)
unique(rank_by_year[rank_by_year$region=='MIDDLE EAST',]$country)
View(rank_by_year)
# Caribbean:
caribbean <- filterByRegion(rank_by_year, "CARIBBEAN")
caribbean <- cleanRegionData(caribbean, replace_0="yes", remove_0709="yes")
View(caribbean)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa,
"caribbean"=caribbean)
dfWriteJSON(region_df_list)
View(rank_by_year)
# Caribbean:
caribbean <- filterByRegion(rank_by_year, "CARIBBEAN")
caribbean <- cleanRegionData(caribbean, replace_0="yes", remove_0709="yes")
caribbean_names_old <- list('Dominican Republic', 'St. Vincent and the Grenadines', 'Trinidad and Tobago',
'Antigua and Barbuda',)
caribbean_names_new <- list('Dominican Rep.', 'St. Vincent (SVG)', 'Trinidad & Tobago',
'Antigua & Barbuda')
caribbean_names_old <- list('Dominican Republic', 'St. Vincent and the Grenadines', 'Trinidad and Tobago',
'Antigua and Barbuda')
caribbean_names_new <- list('Dominican Rep.', 'St. Vincent (SVG)', 'Trinidad & Tobago',
'Antigua & Barbuda')
caribbean <- replaceNames(caribbean, 4, africa_names_old, africa_names_new)
# Caribbean:
caribbean <- filterByRegion(rank_by_year, "CARIBBEAN")
caribbean <- cleanRegionData(caribbean, replace_0="yes", remove_0709="yes")
caribbean_names_old <- list('Dominican Republic', 'St. Vincent and the Grenadines', 'Trinidad and Tobago',
'Antigua and Barbuda')
caribbean_names_new <- list('Dominican Rep.', 'St. Vincent (SVG)', 'Trinidad & Tobago',
'Antigua & Barbuda')
caribbean <- replaceNames(caribbean, 4, caribbean_names_old, caribbean_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa,
"caribbean"=caribbean)
dfWriteJSON(region_df_list)
# Caribbean:
caribbean <- filterByRegion(rank_by_year, "CARIBBEAN")
caribbean <- cleanRegionData(caribbean, replace_0="yes", remove_0709="yes")
caribbean_names_old <- list('Dominican Republic', 'St. Vincent and the Grenadines', 'Trinidad and Tobago',
'Antigua and Barbuda')
caribbean_names_new <- list('Dominican Rep.', 'St. Vincent (SVG)', 'Trinidad & Tob.',
'Antigua & Barbuda')
caribbean <- replaceNames(caribbean, 4, caribbean_names_old, caribbean_names_new)
## Export to JSON:
region_df_list <- list("asia"=asia, "europe"=europe, "africa"=africa,
"caribbean"=caribbean)
dfWriteJSON(region_df_list)
